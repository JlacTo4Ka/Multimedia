# Лабораторные работы по курсу "Методы, средства и технологии мультимедиа" (8 семестр)

студент: Павловский Алексей Валерьевич 
группа:  М8О-410Б-21

---

## Лабораторная работа №6 (Проведение исследований с моделями классификации)

### 1. Собственная трансформерная реализация 
| Модель               | Эпоха 1 val_acc | Эпоха 2 val_acc | Эпоха 3 val_acc | Лучший val_acc | val_f1  |
|:--------------------:|:---------------:|:---------------:|:---------------:|:--------------:|:-------:|
| **CustomTransformer**|      0.2127     |      0.2936     |      0.3747     |     0.3747     | 0.2428  |

> **Комментарий:**  
> – Без улучшений («baseline») трансформер едва достигает 37 % на валидации.  
> – F1-score также очень низкий, всего 0.24.

---

### 2. Собственная сверточная реализация (CustomCNN)
| Модель         | Эпоха 1 val_acc | Эпоха 2 val_acc | Эпоха 3 val_acc | Эпоха 4 val_acc | Эпоха 5 val_acc | Лучший val_acc | val_f1  |
|:--------------:|:---------------:|:---------------:|:---------------:|:---------------:|:---------------:|:--------------:|:-------:|
| **CustomCNN**  |      0.6565     |      0.7892     |      0.8551     |      0.8856     |      0.8841     |     0.8856     | 0.8130  |
| **+ улучшения**|      0.4838     |      0.4958     |      0.4930     |        –        |        –        |     0.4958     | 0.4535  |

> **Комментарий:**  
> – «Чистая» CNN быстро сходится и к 5-й эпохе даёт почти 89 % accuracy и F1≈0.81.  
> – При добавлении агрессивных аугментаций и смене оптимизатора качество резко *упало* до ≈50 %.  

---

### 3. Готовые модели из torchvision

| Модель     | baseline val_acc | baseline val_f1 | improved val_acc | improved val_f1 |
|:----------:|:----------------:|:---------------:|:----------------:|:---------------:|
| **ResNet18** |     0.8374      |     0.8336      |     0.8199       |     0.8150      |
| **ViT-B_16** |     0.2271      |     0.1944      |     0.8605       |     0.8605      |

> **Комментарий:**  
> – **ResNet18** на мощных аугментациях слегка проседает (83.7→81.9 %).  
> – **ViT-B_16** без «прокачки» почти не обучается (22 %), но с улучшенным бейзлайном достигает ≈86 % и F1≈0.86.

---

## Общие выводы

1. **Собственная трансформерная реализация** в своей «чистой» реализации уступает всем остальным: нужна доработка архитектуры или предобученные веса.  
2. **Собственная сверточная реализация** показывает отличный baseline, но текущие кастомные аугментации оказались чрезмерными — они ухудшили качество.  
3. Из готовых моделей наиболее стабильна **ResNet18**, а **ViT-B_16** выигрывает только при правильно настроенном пайплайне (сильные аугментации + оптимальные гиперпараметры).  

---

## Лабораторная работа №7 (Проведение исследований с моделями классификации)

| Модель                                    | Val Loss | Val IoU |
|-------------------------------------------|---------:|--------:|
| **2. Baseline**<br>UNet(ResNet-34) + BCE   |   0.0991 |  0.9497 | 
| **3. Улучшенный**<br>UNet(ResNet-50) + BCE+Dice |   0.0699 |  0.9478 |
| **4a. Обычный Baseline**<br>Моя UNet + BCE |   0.2516 |  0.8559 | 
| **4b. Улучшенный Improved**<br>Моя UNet + CombinedLoss |   0.1853 |  0.8530 | 

**Общий вывод:**  
- **Предобученные энкодеры** (ResNet-34/50) дают существенно более высокие IoU (~95 %) и низкий Loss (0.07=0.10) по сравнению с собственной UNet (0.86 IoU, Loss 0.18–0.25).  
- **Комбинированный loss (BCE+Dice)** на ResNet-50 снизил Val Loss вдвое (0.07 vs 0.10) при сохранении IoU, что говорит о более уверенных предсказаниях и лучшей оптимизации границ объектов.  
- **Собственная реализация** тоже выигрывает от CombinedLoss (Loss 0.18 vs 0.25), но остаётся заметно ниже по IoU (~85 %) по сравнению с вариантами на базе `segmentation_models.pytorch`. Однако результатами я остался доволен.  
- Метрика Pixel Accuracy (PA ≈ 11) является относительной из-за масштабирования, но её стабильность демонстрирует отсутствие сдвигов между обучением и валидацией.  

> **Итог:** для быстрых и надёжных результатов предпочтительнее использовать готовые предобученные энкодеры и комбинированные функции потерь, тогда как полностью «с нуля» реализованные сети требуют дополнительной архитектурной и гиперпараметрической доработки.

---

## Лабораторная работа №8 (Проведение исследований моделями обнаружения и распознавания объектов)

### 1. Детекция (YOLOv8)

| Метрика       | Baseline YOLO | Improved YOLO | Δ             |
|---------------|---------------|---------------|---------------|
| Precision     | 0.865         | 0.859         | −0.006        |
| Recall        | 0.736         | 0.732         | −0.004        |
| mAP@0.5       | 0.805         | 0.790         | −0.015        |
| mAP@0.5–0.95  | 0.351         | 0.346         | −0.005        |

### 2. Сегментация

| Метрика       | Baseline Seg | Improved Seg | Δ             |
|---------------|--------------|--------------|---------------|
| IoU           | 0.0443       | 0.2164       | +0.1721       |
| Precision     | 0.1434       | 0.2953       | +0.1519       |
| Recall        | 0.0531       | 0.3523       | +0.2992       |
| mAP@0.5       | 0.2442       | 0.3701       | +0.1259       |

- **Существенный прирост** качества: за счёт аугментаций, BatchNorm, skip-связей и комбинированного loss собственная модель поднялась по всем метрикам.
- IoU выросла почти в 5×, mAP—в полтора раза, что демонстрирует эффективность предлагаемого «улучшенного бейзлайна» для сегментации.

### Общий вывод по лабораторной работе

1. **Детекция** семейства YOLOv8 на спутниковом датасете «boats» показала высокие метрики уже в базовом варианте (mAP@0.5 ≈ 0.8). Улучшения за счёт аугментаций дали небольшой регресс, но позволили выявить чувствительность модели к параметрам регуляризации.
2. **Собственная сегментация** из простого U-Net-подобного блока (SimpleSeg) была изначально слабой, но после включения аугментаций, нормализаций и skip-связей (ImprovedSeg) показала значительный рост по IoU, Precision и mAP.
